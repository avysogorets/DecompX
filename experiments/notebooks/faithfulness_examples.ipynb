{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da27efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def preprocess_function_wrapped(tokenizer):\n",
    "    def preprocess_function(examples):\n",
    "        # Tokenize the texts\n",
    "        args = (\n",
    "            (examples[SENTENCE1_KEY],) if SENTENCE2_KEY is None else (examples[SENTENCE1_KEY], examples[SENTENCE2_KEY])\n",
    "        )\n",
    "        result = tokenizer(*args, padding=False, max_length=MAX_LENGTH, truncation=True)\n",
    "        return result\n",
    "    return preprocess_function\n",
    "\n",
    "def token_id_to_tokens_mapper(tokenizer, sample):\n",
    "    length = len(sample[\"input_ids\"])\n",
    "    return tokenizer.convert_ids_to_tokens(sample[\"input_ids\"])[:length], length\n",
    "\n",
    "def load_globenc(path, no_cls=False, no_sep=False):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    if no_cls:\n",
    "        data[\"tokens\"] = [d[1:] for d in data[\"tokens\"]]\n",
    "        data[\"globenc\"] = [np.array(d)[:, 1:] for d in data[\"globenc\"]]\n",
    "    if no_sep:\n",
    "        data[\"tokens\"] = [d[:-1] for d in data[\"tokens\"]]\n",
    "        data[\"globenc\"] = [np.array(d)[:, :-1] for d in data[\"globenc\"]]\n",
    "    data = pd.DataFrame(data)\n",
    "    before_size = len(data)\n",
    "    data = data[data[\"tokens\"].map(len) > 1]\n",
    "    after_size = len(data)\n",
    "    print(f\"Read {path}: {before_size}->{after_size} \")\n",
    "    return data.to_dict(orient=\"list\"), data.index\n",
    "\n",
    "def load_pickle(path, no_cls=False, no_sep=False):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def print_globenc(globenc, tokenized_text, discrete=False, prefix=\"\", del_ratio=0.0):\n",
    "    if len(globenc.shape) == 2:\n",
    "        globenc = np.expand_dims(globenc, axis=0)\n",
    "    norm_cls = globenc[:, 0, :]\n",
    "    norm_cls = np.flip(norm_cls, axis=0)\n",
    "    row_sums = norm_cls.max(axis=1)\n",
    "    norm_cls = norm_cls / row_sums[:, np.newaxis]\n",
    "    html = prefix\n",
    "    if discrete:\n",
    "        cls_attention = np.argsort(np.argsort(norm_cls[0, :])) / len(norm_cls[0, :])\n",
    "    else:\n",
    "        cls_attention = norm_cls[0, :]\n",
    "    for i in range(len(tokenized_text)):\n",
    "        del_count = np.floor(len(norm_cls[0, :]) * del_ratio)\n",
    "        ranks = np.argsort(np.argsort(norm_cls[0, :]))\n",
    "        if len(ranks) - ranks[i] > del_count:\n",
    "            color = f\"background-color: rgba({cls_attention[i]*255}, {cls_attention[i]*255}, 0, {cls_attention[i] / 1.5}); \"\n",
    "        else:\n",
    "            color = f\"background-color: rgba({cls_attention[i]*255}, 0, 0, {cls_attention[i] / 1.5}); \"\n",
    "        html += (f\"<span style='\"\n",
    "                 f\"{color}\"\n",
    "#                  f\"background-color: rgba(200, {cls_attention[i]*255}, 10, 1.0); \"\n",
    "#                  f\"font-size: {int(cls_attention[i]*18 + 1)}px; \"\n",
    "#                  f\"font-weight: {int(cls_attention[i]*900)};\"\n",
    "                 f\"font-weight: {int(800)};\"\n",
    "                 \"'>\")\n",
    "        html += tokenized_text[i]\n",
    "        html += \"</span> \"\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0853e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH =  \"/home/modaresi/projects/globenc_analysis/outputs/models/output_mnli_bert-base-uncased_0001_SEED0042/checkpoint-61360\"\n",
    "TASK = \"mnli\"\n",
    "SET = \"validation_matched\"  # train/validation/validation_matched\n",
    "\n",
    "# MODEL_PATH = \"/home/modaresi/projects/globenc_analysis/outputs/models/output_sst2_bert-large-uncased_0001_SEED0042/checkpoint-10525\"\n",
    "# TASK = \"sst2\"\n",
    "# SET = \"validation\"\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be206e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "actual_task = \"mnli\" if TASK == \"mnli-mm\" else TASK\n",
    "dataset = datasets.load_dataset(\"glue\", actual_task)\n",
    "metric = datasets.load_metric('glue', actual_task)\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "SENTENCE1_KEY, SENTENCE2_KEY = task_to_keys[TASK]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d8c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "model.to(torch.device(\"cuda:0\"))\n",
    "model.eval()\n",
    "\n",
    "def preprocess(e):\n",
    "    e[\"premise\"] = e[\"premise\"].replace(\".\", \"\")\n",
    "    e[\"hypothesis\"] = e[\"hypothesis\"].replace(\".\", \"\")\n",
    "    return e\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, use_fast=True, max_length=MAX_LENGTH)\n",
    "\n",
    "sel_dataset = dataset[SET].map(preprocess)\n",
    "sel_dataset = sel_dataset.map(preprocess_function_wrapped(tokenizer), batched=True, batch_size=1024)\n",
    "dataset_size = len(sel_dataset)\n",
    "print(dataset_size)\n",
    "\n",
    "dataset[SET][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a904cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sel_dataset[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c0573",
   "metadata": {},
   "source": [
    "# Compute Faithfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTAs_dir = \"/home/modaresi/projects/globenc_analysis/outputs/HTAs\"\n",
    "globencs_v2_dir = \"/home/modaresi/projects/globenc_analysis/outputs/globencs_elementwise\"\n",
    "globencs_dir = \"/home/modaresi/projects/globenc_analysis/outputs/globencs\"\n",
    "saliencies_dir = \"/home/modaresi/projects/globenc_analysis/outputs/saliencies\"\n",
    "configs = {\n",
    "    \"mnli-val\": {\n",
    "        \"hta_path\": lambda epoch : f\"{HTAs_dir}/mnli_validation_matched_bert-base-uncased_0001_SEED0042_checkpoint-{epoch*12272}.pkl\",\n",
    "        \"globenc_path\": lambda epoch : f\"{globencs_dir}/mnli-e{epoch}_validation_matched_bert-base-uncased.pickle\",\n",
    "        \"globenc_v2_path\": lambda epoch : f\"{globencs_v2_dir}/mnli-e{epoch}_validation_matched_bert-base-uncased.pickle\",\n",
    "        \"saliency_path\": lambda epoch : f\"{saliencies_dir}/mnli_bert-base-uncased_0001_SEED0042_checkpoint-{epoch*12272}.npy\",\n",
    "        \"hf_ds\": \"mnli\",\n",
    "    },\n",
    "    \"sst2-val\": {\n",
    "        \"hta_path\": lambda epoch : f\"{HTAs_dir}/sst2_validation_bert-base-uncased_0001_SEED0042_checkpoint-{epoch*2105}.pkl\",\n",
    "        \"globenc_path\": lambda epoch : f\"{globencs_dir}/sst2-e{epoch}_validation_bert-base-uncased.pickle\",\n",
    "        \"globenc_v2_path\": lambda epoch : f\"{globencs_v2_dir}/sst2-e{epoch}_validation_bert-base-uncased.pickle\",\n",
    "        \"saliency_path\": lambda epoch : f\"{saliencies_dir}/sst2_bert-base-uncased_0001_SEED0042_checkpoint-{epoch*2105}.npy\",\n",
    "        \"hf_ds\": \"sst2\",\n",
    "    }\n",
    "}\n",
    "\n",
    "CONFIG_NAME = \"mnli-val\"\n",
    "# CONFIG_NAME = \"sst2-val\"\n",
    "CONFIG = configs[CONFIG_NAME]\n",
    "EPOCH = 5\n",
    "\n",
    "globencs, DATASET_KEEP_IDX = load_globenc(CONFIG[\"globenc_path\"](EPOCH), no_cls=False, no_sep=False)\n",
    "globencs_v2, DATASET_KEEP_IDX = load_globenc(CONFIG[\"globenc_v2_path\"](EPOCH), no_cls=False, no_sep=False)\n",
    "htas = load_pickle(CONFIG[\"hta_path\"](EPOCH))\n",
    "saliencies = np.load(CONFIG[\"saliency_path\"](EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f73cbf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "INVERTED = False  # True=MaskMax, False=MaskMin\n",
    "MASK = True\n",
    "for exp_type in [\"globencV1\", \"globencV2\", \"salsNorm\"]:\n",
    "    print(\"Masking based on\", exp_type)\n",
    "    results[exp_type] = dict()\n",
    "    for i in [0, 7]:\n",
    "        results[exp_type][f\"{i*10}%\"] = {\"preds\": [], \"correct\": [], \"logits\": []}\n",
    "        # Masks i*10% of the tokens -- based on their attribution metric value\n",
    "        def mapping_masks(example):\n",
    "            length = np.sum(example[\"attention_mask\"])\n",
    "            if exp_type == \"globencV1\":\n",
    "                sal_rank = globencs['globenc'][example[\"idx\"]][0][:length].argsort()\n",
    "            elif exp_type == \"globencV2\":\n",
    "                sal_rank = globencs_v2['globenc'][example[\"idx\"]][0][:length].argsort()\n",
    "            elif exp_type == \"salsNorm\":\n",
    "                sal_rank = saliencies[example[\"idx\"]][:length].argsort()\n",
    "            elif exp_type == \"hta\":\n",
    "                sal_rank = htas[\"HTAs\"][example[\"idx\"]][0][:length].argsort()\n",
    "            # Exclude CLS and SEPs\n",
    "            sal_rank = sal_rank[~np.in1d(sal_rank, np.argwhere(np.array(example[\"input_ids\"]) < 103).flatten())]\n",
    "            mask_count = int(np.floor(len(sal_rank) * i / 10.0))\n",
    "            if mask_count == 0:\n",
    "                masks = []\n",
    "            else:\n",
    "                if INVERTED:\n",
    "                    masks = sal_rank[-mask_count:]\n",
    "                else:\n",
    "                    masks = sal_rank[:mask_count]\n",
    "            replacement_token = tokenizer.mask_token_id if MASK else tokenizer.pad_token_id\n",
    "            if not MASK:\n",
    "                example[\"attention_mask\"] = [0 if j in masks else example[\"attention_mask\"][j] for j in range(length)]\n",
    "            example[\"input_ids\"] = [replacement_token if j in masks else example[\"input_ids\"][j] for j in range(length)]\n",
    "            return example\n",
    "        \n",
    "        modified_set = sel_dataset.map(mapping_masks)\n",
    "\n",
    "        modified_set.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "        collator = DataCollatorWithPadding(tokenizer, True, MAX_LENGTH, return_tensors=\"pt\")\n",
    "        dataloader = torch.utils.data.DataLoader(modified_set, batch_size=BATCH_SIZE, collate_fn=collator, shuffle=False)\n",
    "        steps = int(np.ceil(dataset_size / BATCH_SIZE))\n",
    "        num_labels = len(set(modified_set['label']))\n",
    "\n",
    "        it = iter(dataloader)\n",
    "        y_preds = torch.zeros(size=(dataset_size,)).cuda()\n",
    "        y_trues = torch.zeros(size=(dataset_size,), dtype=torch.int32).cuda()\n",
    "        y_logits = list()\n",
    "        with torch.no_grad():\n",
    "            for j in tqdm(range(steps), desc=f\"{exp_type}-{i*10}%\"):\n",
    "                batch = next(it)\n",
    "                batch = {k: v.to(torch.device('cuda:0')) for k, v in batch.items()}\n",
    "                inputs = {\n",
    "                    'input_ids': batch['input_ids'],\n",
    "                    'attention_mask': batch['attention_mask'],\n",
    "                    'token_type_ids': batch['token_type_ids'],\n",
    "                }\n",
    "                y_trues[j*BATCH_SIZE:(j+1)*BATCH_SIZE] = batch['labels']\n",
    "                output = model(**batch)\n",
    "                y_preds[j*BATCH_SIZE:(j+1)*BATCH_SIZE] = torch.argmax(output.logits, dim=-1)\n",
    "                y_logits.extend(output.logits.cpu().numpy())\n",
    "        \n",
    "        results[exp_type][f\"{i*10}%\"][\"correct\"] = (y_trues == y_preds).cpu().numpy()\n",
    "        results[exp_type][f\"{i*10}%\"][\"preds\"] = y_preds.cpu().numpy()\n",
    "        results[exp_type][f\"{i*10}%\"][\"logits\"] = np.array(y_logits)\n",
    "        replacement_token = tokenizer.mask_token_id if MASK else tokenizer.pad_token_id\n",
    "        results[exp_type][f\"{i*10}%\"][\"modified_set\"] = modified_set[\"input_ids\"]\n",
    "        # print(results[exp_type][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3210d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = \"70%\"\n",
    "labels = sel_dataset[\"label\"]\n",
    "for method in [\"globencV1\", \"globencV2\", \"salsNorm\"]:\n",
    "    idxs = (labels == results[method][\"0%\"][\"preds\"])\n",
    "    print(method, np.mean(results[method][\"0%\"][\"correct\"][idxs]))\n",
    "    print(method, np.mean(results[method][P][\"correct\"][idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9accb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (results[\"globencV1\"][\"0%\"][\"correct\"] == results[\"globencV2\"][\"0%\"][\"correct\"]).all()\n",
    "\n",
    "diff_indices = results[\"globencV1\"][P][\"correct\"] != results[\"globencV2\"][P][\"correct\"]\n",
    "diff_indices_correct_preds = diff_indices & (labels == results[\"globencV1\"][\"0%\"][\"preds\"])\n",
    "v1_error_idxs = np.where(diff_indices_correct_preds & (results[\"globencV1\"][P][\"correct\"] == False))[0]\n",
    "v2_error_idxs = np.where(diff_indices_correct_preds & (results[\"globencV2\"][P][\"correct\"] == False))[0]\n",
    "sal_error_idxs = np.where(diff_indices_correct_preds & (results[\"salsNorm\"][P][\"correct\"] == False))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5a37a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in v1_error_idxs[:]:\n",
    "    if len(globencs[\"tokens\"][idx]) > 20 or len(globencs[\"tokens\"][idx]) < 18:\n",
    "        continue\n",
    "#     idx = 5705\n",
    "    print(\"idx:\", idx)\n",
    "    print(\"LABEL:\", sel_dataset[\"label\"][idx])\n",
    "    print(f\"G_V1 Pred: {results['globencV1']['0%']['preds'][idx]}->{results['globencV1'][P]['preds'][idx]} {results['globencV1']['0%']['logits'][idx]}->{results['globencV1'][P]['logits'][idx]}\")\n",
    "    print(f\"G_V2 Pred: {results['globencV2']['0%']['preds'][idx]}->{results['globencV2'][P]['preds'][idx]} {results['globencV2']['0%']['logits'][idx]}->{results['globencV2'][P]['logits'][idx]}\")\n",
    "    print(f\"salN Pred: {results['salsNorm']['0%']['preds'][idx]}->{results['salsNorm'][P]['preds'][idx]} {results['salsNorm']['0%']['logits'][idx]}->{results['salsNorm'][P]['logits'][idx]}\")\n",
    "    # print_globenc(globencs[\"globenc\"][idx], globencs[\"tokens\"][idx], prefix=f\"g_v1: \")\n",
    "    # print_globenc(globencs_v2[\"globenc\"][idx], globencs[\"tokens\"][idx], prefix=f\"g_v2: \")\n",
    "    length = len(globencs[\"tokens\"][idx][1:-1])\n",
    "    print_globenc(globencs[\"globenc\"][idx][:, 1:-1], globencs[\"tokens\"][idx][1:-1], prefix=f\"G_V1: \", discrete=True, del_ratio=0.33)\n",
    "    print_globenc(globencs_v2[\"globenc\"][idx][:, 1:-1], globencs_v2[\"tokens\"][idx][1:-1], prefix=f\"G_V2: \", discrete=True, del_ratio=0.33)\n",
    "    print_globenc(np.expand_dims(saliencies[idx][1:length+1], 0), globencs_v2[\"tokens\"][idx][1:-1], prefix=f\"S_V0: \", discrete=True, del_ratio=0.33)\n",
    "    ### REAL MASKED VERSIONS:\n",
    "    print_globenc(globencs[\"globenc\"][idx][:, 1:-1], tokenizer.convert_ids_to_tokens(results[\"globencV1\"][P][\"modified_set\"][idx][1:-1]), prefix=f\"G_V1: \", discrete=True, del_ratio=0.33)\n",
    "    print_globenc(globencs_v2[\"globenc\"][idx][:, 1:-1], tokenizer.convert_ids_to_tokens(results[\"globencV2\"][P][\"modified_set\"][idx][1:-1]), prefix=f\"G_V2: \", discrete=True, del_ratio=0.33)\n",
    "    print_globenc(np.expand_dims(saliencies[idx][1:length+1], 0), tokenizer.convert_ids_to_tokens(results[\"salsNorm\"][P][\"modified_set\"][idx][1:-1]), prefix=f\"S_V0: \", discrete=True, del_ratio=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3309f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5705\n",
    "print(tokenizer.convert_ids_to_tokens(results[\"globencV1\"][\"30%\"][\"modified_set\"][idx]))\n",
    "print(tokenizer.convert_ids_to_tokens(results[\"globencV2\"][\"30%\"][\"modified_set\"][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"globencV1\"][\"30%\"][\"modified_set\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db655c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"globencV2\"][\"30%\"][\"modified_set\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aaddca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
